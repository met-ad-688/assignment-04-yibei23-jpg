---
title: Assignment 04
author:
  - name: Yibei Yu
    affiliations:
      - id: bu
        name: Boston University
        city: Boston
        state: MA
number-sections: true
date: '2025-10-7'
date-modified: today
date-format: long
format:
  html:
    theme: cerulean
    toc: true
    toc-depth: 2
execute:
  echo: false
  eval: true
  freeze: auto
  fig-path: figure-html
---

Github Link: https://github.com/met-ad-688/assignment-04-yibei23-jpg

"This homework was done with the help of AI for code debugging."

# Setup and Data Loading
```{python}
from pyspark.sql import SparkSession
spark = SparkSession.builder.appName("LightcastData").getOrCreate()

df = spark.read.option("header", "true").option("inferSchema", "true") \
    .option("multiLine", "true").option("escape", "\"") \
    .csv("data/lightcast_job_postings.csv")

df.show(5)
#df.printSchema()
```
# Feature Engineering
```{python}
from pyspark.sql.functions import pow, to_date, unix_timestamp
from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler

df = df.na.drop(subset=["SALARY", "MIN_YEARS_EXPERIENCE", "ONET_NAME", "COMPANY_NAME"])
df = df.withColumn("POSTED_DATE", to_date("POSTED", "M/d/yyyy"))
df = df.withColumn("POSTED_DATE_NUM", unix_timestamp("POSTED_DATE"))

df = df.withColumn("MIN_YEARS_EXPERIENCE_SQ", pow(df["MIN_YEARS_EXPERIENCE"], 2))

cont_features = ["MIN_YEARS_EXPERIENCE", "MAX_YEARS_EXPERIENCE", "POSTED_DATE_NUM", "MIN_YEARS_EXPERIENCE_SQ"]
cat_features = ["ONET_NAME", "COMPANY_NAME"]
indexers = [StringIndexer(inputCol=c, outputCol=c+"_idx", handleInvalid="keep") for c in cat_features]
encoders = [OneHotEncoder(inputCol=c+"_idx", outputCol=c+"_ohe") for c in cat_features]

df = df.na.drop(subset=[
    "SALARY",
    "MIN_YEARS_EXPERIENCE",
    "MAX_YEARS_EXPERIENCE",
    "POSTED_DATE_NUM",
    "MIN_YEARS_EXPERIENCE_SQ",
    "ONET_NAME",
    "COMPANY_NAME"
])

assembler_poly = VectorAssembler(
    inputCols=cont_features + [c+"_ohe" for c in cat_features],
    outputCol="features_poly"
)
assembler_simple = VectorAssembler(
    inputCols=["MIN_YEARS_EXPERIENCE", "MAX_YEARS_EXPERIENCE", "POSTED_DATE_NUM"] + [c+"_ohe" for c in cat_features],
    outputCol="features"
)

train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)

print("Feature engineering complete.")
print(f"Total records after cleaning: {df.count():,}")
print(f"Training set size: {train_data.count():,}")
print(f"Test set size: {test_data.count():,}")
```

# Polynomial Regression
```{python}
from pyspark.ml.regression import GeneralizedLinearRegression
from pyspark.ml import Pipeline
import pandas as pd
import matplotlib.pyplot as plt
from IPython.display import Image, display

glr_poly = GeneralizedLinearRegression(
    featuresCol="features_poly",
    labelCol="SALARY",
    family="gaussian",
    link="identity",
    regParam=0.1,      
    maxIter=50
)

pipeline_poly = Pipeline(stages=indexers + encoders + [assembler_poly, glr_poly])
model_poly = pipeline_poly.fit(train_data)
predictions_poly = model_poly.transform(test_data)

summary_poly = model_poly.stages[-1].summary
intercept = model_poly.stages[-1].intercept

coefs  = [intercept] + list(model_poly.stages[-1].coefficients)
stderr = summary_poly.coefficientStandardErrors
tvals  = summary_poly.tValues
pvals  = summary_poly.pValues

min_len = min(len(coefs), len(stderr), len(tvals), len(pvals))
coefs, stderr, tvals, pvals = coefs[:min_len], stderr[:min_len], tvals[:min_len], pvals[:min_len]

coef_table_poly = pd.DataFrame({
    "Feature": ["Intercept"] + [f"coef_{i}" for i in range(1, min_len)],
    "Coefficient": coefs,
    "StdErr": stderr,
    "tValue": tvals,
    "pValue": pvals,
})
coef_table_poly["95% CI Lower"] = coef_table_poly["Coefficient"] - 1.96 * coef_table_poly["StdErr"]
coef_table_poly["95% CI Upper"] = coef_table_poly["Coefficient"] + 1.96 * coef_table_poly["StdErr"]

print("=== Polynomial Regression Coefficient Significance Table ===")
print(coef_table_poly.head(10))
print(f"AIC = {summary_poly.aic:.2f}, Dispersion = {summary_poly.dispersion:.4f}")

plt.figure(figsize=(6, 5))
plt.scatter(
    predictions_poly.select("SALARY").toPandas(),
    predictions_poly.select("prediction").toPandas(),
    alpha=0.6,
    color="green"
)
plt.plot(
    [predictions_poly.agg({"SALARY": "min"}).first()[0],
     predictions_poly.agg({"SALARY": "max"}).first()[0]],
    [predictions_poly.agg({"SALARY": "min"}).first()[0],
     predictions_poly.agg({"SALARY": "max"}).first()[0]],
    color="red", linestyle="--"
)
plt.title("Polynomial GLR: Actual vs Predicted")
plt.xlabel("Actual Salary")
plt.ylabel("Predicted Salary")
plt.tight_layout()

plt.savefig("poly_glr_actual_vs_predicted.png", bbox_inches="tight")
plt.show()
display(Image(filename="poly_glr_actual_vs_predicted.png"))
```
**Analysis**
The polynomial generalized linear regression model captures the nonlinear effect between experience and salary. The scatter plot (poly_glr_actual_vs_predicted.png) shows that the predicted values ​​are tightly clustered around the red line, indicating that the model accurately captures salary trends for most positions. This model achieves an RMSE of ≈ 23,914 and an R² of ≈ 0.573, slightly better than the baseline GLR. While this improvement is modest, the reduction in error and the lower AIC/BIC values ​​indicate that the quadratic transformation provides a slight improvement without overfitting.

# Linear Regression
```{python}
from pyspark.ml.regression import GeneralizedLinearRegression
from pyspark.ml import Pipeline
import pandas as pd
import matplotlib.pyplot as plt
from IPython.display import Image, display

glr_simple = GeneralizedLinearRegression(
    featuresCol="features",
    labelCol="SALARY",
    family="gaussian",
    link="identity",
    regParam=0.1,   # small regularization avoids singularities
    maxIter=50
)

pipeline_simple = Pipeline(stages=indexers + encoders + [assembler_simple, glr_simple])
model_simple = pipeline_simple.fit(train_data)
predictions_simple = model_simple.transform(test_data)

summary_simple = model_simple.stages[-1].summary

intercept = model_simple.stages[-1].intercept

coefs  = [intercept] + list(model_simple.stages[-1].coefficients)
stderr = summary_simple.coefficientStandardErrors
tvals  = summary_simple.tValues
pvals  = summary_simple.pValues

min_len = min(len(coefs), len(stderr), len(tvals), len(pvals))
coefs, stderr, tvals, pvals = coefs[:min_len], stderr[:min_len], tvals[:min_len], pvals[:min_len]

coef_table_simple = pd.DataFrame({
    "Feature": ["Intercept"] + [f"coef_{i}" for i in range(1, min_len)],
    "Coefficient": coefs,
    "StdErr": stderr,
    "tValue": tvals,
    "pValue": pvals,
})
coef_table_simple["95% CI Lower"] = coef_table_simple["Coefficient"] - 1.96 * coef_table_simple["StdErr"]
coef_table_simple["95% CI Upper"] = coef_table_simple["Coefficient"] + 1.96 * coef_table_simple["StdErr"]

print("=== GLR (Simple) Coefficient Significance Table ===")
print(coef_table_simple.head(10))
print(f"AIC = {summary_simple.aic:.2f}, Dispersion = {summary_simple.dispersion:.4f}")

plt.figure(figsize=(6, 5))
plt.scatter(
    predictions_simple.select("SALARY").toPandas(),
    predictions_simple.select("prediction").toPandas(),
    alpha=0.6,
    color="blue"
)
plt.plot(
    [predictions_simple.agg({"SALARY": "min"}).first()[0],
     predictions_simple.agg({"SALARY": "max"}).first()[0]],
    [predictions_simple.agg({"SALARY": "min"}).first()[0],
     predictions_simple.agg({"SALARY": "max"}).first()[0]],
    color="red", linestyle="--"
)
plt.title("GLR (Simple): Actual vs Predicted")
plt.xlabel("Actual Salary")
plt.ylabel("Predicted Salary")
plt.tight_layout()
plt.savefig("glr_actual_vs_predicted.png", bbox_inches="tight")
plt.show()
display(Image(filename="glr_actual_vs_predicted.png"))

```
**Analysis**

The baseline GLR contains only linear terms. The scatter plot (glr_actual_vs_predicted.png) shows a clear upward trend, indicating a strong linear relationship between experience and salary. The RMSE is ≈ 23,996, and the R² is ≈ 0.570, nearly identical to the polynomial version. Due to its simplicity, low computational cost, and comparable accuracy, the simple GLR provides an excellent benchmark. However, its slightly higher AIC/BIC values ​​indicate a slightly lower fit efficiency compared to the polynomial version.

# Random Forest Regressor
```{python}
from pyspark.ml.regression import RandomForestRegressor
from pyspark.ml import Pipeline
from pyspark.ml.evaluation import RegressionEvaluator
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

rf = RandomForestRegressor(
    featuresCol="features_poly",
    labelCol="SALARY",
    numTrees=200,
    maxDepth=8,
    seed=42
)

pipeline_rf = Pipeline(stages=indexers + encoders + [assembler_poly, rf])
rf_model = pipeline_rf.fit(train_data)
predictions_rf = rf_model.transform(test_data)

evaluator = RegressionEvaluator(labelCol="SALARY", predictionCol="prediction", metricName="rmse")
rmse_rf = evaluator.evaluate(predictions_rf)
r2_rf = RegressionEvaluator(labelCol="SALARY", predictionCol="prediction", metricName="r2").evaluate(predictions_rf)

print(f"Random Forest RMSE: {rmse_rf:.2f}")
print(f"Random Forest R²: {r2_rf:.4f}")

importances = rf_model.stages[-1].featureImportances.toArray()

cont_features = [
    "MIN_YEARS_EXPERIENCE",
    "MAX_YEARS_EXPERIENCE",
    "POSTED_DATE_NUM",
    "MIN_YEARS_EXPERIENCE_SQ"
]
cat_features = ["ONET_NAME", "COMPANY_NAME"]

ohe_sizes = []
for stage in rf_model.stages:
    if stage.__class__.__name__ == "OneHotEncoderModel":
        ohe_sizes.extend(stage.categorySizes)

feature_names = cont_features.copy()
for col, size in zip(cat_features, ohe_sizes):
    feature_names.extend([f"{col}_{i}" for i in range(size)])

if len(feature_names) < len(importances):
    feature_names.extend([f"unknown_{i}" for i in range(len(importances) - len(feature_names))])
elif len(feature_names) > len(importances):
    feature_names = feature_names[:len(importances)]

top_n = 15
indices = np.argsort(importances)[::-1][:top_n]
top_features = [feature_names[i] for i in indices]
top_importances = importances[indices]

plt.figure(figsize=(10, 6))
plt.barh(range(top_n), top_importances[::-1], align="center")
plt.yticks(range(top_n), [f for f in top_features[::-1]])
plt.xlabel("Feature Importance")
plt.title("Random Forest Feature Importance")
plt.tight_layout()
plt.savefig("rf_feature_importance.png")
plt.show()

```
**Analysis**

I used a random forest model with 200 trees and a maximum depth of 8. The resulting RMSE (≈ 25,820) is high, and the R² (≈ 0.50) is low, indicating weak predictive performance. The scatter plots (compare_models.png) show greater dispersion and underestimation at higher salary levels. I also added a feature importance chart (rf_feature_importance.png) to confirm that experience-related variables dominate, with MIN_YEARS_EXPERIENCE, MAX_YEARS_EXPERIENCE, and their squared terms ranking highest. Some company dummy variables contribute little. While tree-based models can capture nonlinearity, they show slight overfitting for common employers and underfitting for rare employers.

# Compare Models
```{python}
from pyspark.ml.evaluation import RegressionEvaluator
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

evaluator_rmse = RegressionEvaluator(labelCol="SALARY", predictionCol="prediction", metricName="rmse")
evaluator_r2   = RegressionEvaluator(labelCol="SALARY", predictionCol="prediction", metricName="r2")
evaluator_mae  = RegressionEvaluator(labelCol="SALARY", predictionCol="prediction", metricName="mae")

rmse_glr = evaluator_rmse.evaluate(predictions_simple)
r2_glr   = evaluator_r2.evaluate(predictions_simple)
mae_glr  = evaluator_mae.evaluate(predictions_simple)
aic_glr  = summary_simple.aic

rmse_poly = evaluator_rmse.evaluate(predictions_poly)
r2_poly   = evaluator_r2.evaluate(predictions_poly)
mae_poly  = evaluator_mae.evaluate(predictions_poly)
aic_poly  = summary_poly.aic

rmse_rf = evaluator_rmse.evaluate(predictions_rf)
r2_rf   = evaluator_r2.evaluate(predictions_rf)
mae_rf  = evaluator_mae.evaluate(predictions_rf)
aic_rf  = "N/A"

results = pd.DataFrame({
    "Model": ["GLR", "Polynomial Regression", "Random Forest"],
    "RMSE": [rmse_glr, rmse_poly, rmse_rf],
    "R²":   [r2_glr, r2_poly, r2_rf],
    "MAE":  [mae_glr, mae_poly, mae_rf],
    "AIC":  [aic_glr, aic_poly, aic_rf]
})
print("=== Model Comparison ===")
print(results)
```

```{python}
plt.figure(figsize=(12, 10))
plt.subplot(2, 2, 1)
plt.scatter(predictions_simple.select("SALARY").toPandas(),
            predictions_simple.select("prediction").toPandas(), alpha=0.5)
plt.title("GLR (Simple): Actual vs Predicted")
plt.xlabel("Actual Salary")
plt.ylabel("Predicted Salary")

plt.subplot(2, 2, 2)
plt.scatter(predictions_poly.select("SALARY").toPandas(),
            predictions_poly.select("prediction").toPandas(), color="green", alpha=0.5)
plt.title("Polynomial GLR: Actual vs Predicted")
plt.xlabel("Actual Salary")
plt.ylabel("Predicted Salary")

plt.subplot(2, 2, 3)
plt.scatter(predictions_rf.select("SALARY").toPandas(),
            predictions_rf.select("prediction").toPandas(), color="orange", alpha=0.5)
plt.title("Random Forest: Actual vs Predicted")
plt.xlabel("Actual Salary")
plt.ylabel("Predicted Salary")

plt.tight_layout()
plt.savefig("compare_models.png")
plt.show()
```
**Analysis**

Comparing all three models, the polynomial generalized linear regression and simple generalized linear regression performed most similarly and achieved the best overall results. The simple generalized linear regression model achieved a root mean square error (RMSE) of approximately 23,996 and an R² of approximately 0.57, while the polynomial generalized linear regression performed slightly better, with an RMSE of approximately 23,914 and an R² of 0.573. Therefore, adding the squared experience term helps better capture the nonlinear relationship between experience and salary. The predictions of both regression models closely follow the red dashed lines in the scatter plots, providing a good fit to the data and nearly identical estimates.

On the other hand, the random forest model performed poorly, with a higher root mean square error of approximately 25,820 and a lower R² of approximately 0.50, indicating less accurate predictions. The distribution of actual and predicted values ​​is more dispersed, especially for higher salary values. Although the feature importance chart indicates that experience-related features are most important, their stability is reduced.

In terms of metrics, the Multinomial Generalized Relative Rate (GLR) also achieved the lowest AIC (approximately 69,871) and BIC (approximately 74,442), indicating the best overall model fit. Simple GLR achieved slightly higher AIC and BIC values ​​of ~70,128 and ~74,892, respectively, but Random Forest does not provide these metrics in Spark. Therefore, the Multinomial GLR* model achieved the best balance between accuracy and interpretability, while Simple GLR still serves as a simpler and faster baseline model.

```{python}
from pyspark.ml.evaluation import RegressionEvaluator
import numpy as np
import pandas as pd

evaluator_rmse = RegressionEvaluator(labelCol="SALARY", predictionCol="prediction", metricName="rmse")

rmse_glr  = evaluator_rmse.evaluate(predictions_simple)
rmse_poly = evaluator_rmse.evaluate(predictions_poly)
rmse_rf   = evaluator_rmse.evaluate(predictions_rf)

summary_glr  = model_simple.stages[-1].summary
summary_poly = model_poly.stages[-1].summary

coefs_glr  = model_simple.stages[-1].coefficients
coefs_poly = model_poly.stages[-1].coefficients

def compute_bic(summary, coefs, n):
    k = len(coefs)
    dispersion = summary.dispersion
    deviance = summary.deviance
    log_likelihood = -0.5 * (n * np.log(2*np.pi) + n * np.log(dispersion) + deviance/dispersion)
    bic = k * np.log(n) - 2 * log_likelihood
    return bic

n_glr  = predictions_simple.count()
n_poly = predictions_poly.count()

aic_glr,  aic_poly  = summary_glr.aic, summary_poly.aic
bic_glr,  bic_poly  = compute_bic(summary_glr, coefs_glr, n_glr), compute_bic(summary_poly, coefs_poly, n_poly)

results = pd.DataFrame({
    "Model": ["GLR (Simple)", "Polynomial GLR", "Random Forest"],
    "RMSE": [rmse_glr, rmse_poly, rmse_rf],
    "AIC": [aic_glr, aic_poly, None],
    "BIC": [bic_glr, bic_poly, None]
}).round(3)

print("=== Model Performance Summary ===")
display(results)
```
**Notes**
This table is added by me to make the data clearer
